pretrained_ckpt: /mnt/pretrained_models/G0Plus_3B_base/checkpoints/g0plus_2k_hours_20261213.pt
use_pretrained_norm_stats: True

# strategy
model_weights_to_bf16: False
enable_bf16_training: True
use_torch_compile: False # As xiao suggests
find_unused_parameters: False

# dataloader
batch_size: 4
num_workers: 4
pin_memory: True
persistent_workers: True

# training period
max_epochs: 30
max_steps: null
grad_accumulation_steps: 1

# optimizer
use_8bit_optimizer: False # AdamW8bit or AdamW
learning_rate: 2.5e-5 # following allen
weight_decay: 1e-6 # following allen
betas: [0.9, 0.999] # G0

# LR scheduler
lr_scheduler_type: "cosine" # LambdaLR, following openpi
warmup_steps: 500 # following allen

max_grad_norm: 1.0

# EMA
use_ema: False
ema: 
  update_after_step: 0 # Step after which to update EMA weights
  power: 0.67

# sync batch normalization
use_sync_bn: False

image_transform:
  - _target_: torchvision.transforms.Resize
    size: [224, 224]
  - _target_: galaxea_fm.transforms.image.ToTensor
  - _target_: torchvision.transforms.Normalize
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]

processor:
  _target_: galaxea_fm.processors.mixture_processor.MixtureProcessor
  embodiment_processors:
    r1lite:
      _target_: galaxea_fm.processors.galaxea_zero_processor.GalaxeaZeroProcessor
      shape_meta: ${data.embodiment_datasets.r1lite.shape_meta}
      num_obs_steps: ${data.obs_size}

      action_state_transforms: 
        - _target_: galaxea_fm.transforms.relative_action.RelativeJointTransform
          keys: [left_arm, right_arm]
        - _target_: galaxea_fm.transforms.misc.WrapStateAngle
          keys: [chassis]

      # action & state normalization
      use_stepwise_action_norm: True
      norm_default_mode: "z-score"
      norm_exception_mode:
        action:
          left_gripper: "0/100"
          right_gripper: "0/100"
  
      action_state_merger: 
        _target_: galaxea_fm.transforms.action_state_merger.ConcatLeftAlign
        action_target_dim: ${model.model_arch.action_dim}
        state_target_dim: ${model.model_arch.proprio_dim}

      # image transform
      train_transforms: 
        head_rgb: ${model.image_transform}
        left_wrist_rgb: ${model.image_transform}
        right_wrist_rgb: ${model.image_transform}

      val_transforms: ${model.processor.embodiment_processors.r1lite.train_transforms}
      num_output_cameras: 3

      # instruction
      use_zh_instruction: False
      drop_high_level_prob: 1.0

      # tokenization
      pad_token_id: ${model.model_arch.pad_token_id}
      image_token_index: ${model.model_arch.image_token_index}
      tokenizer_params: 
        pretrained_model_name_or_path: google/paligemma-3b-pt-224
        local_files_only: False
        token: null                 # fill in the token if you access gated repo, default to None
      max_text_tokens: ${model.model_arch.max_text_tokens}
      max_image_text_tokens: ${model.model_arch.max_image_text_tokens}
      num_input_cameras: ${model.model_arch.num_input_images}
      num_image_tokens_per_camera: ${model.model_arch.vision.num_image_tokens}
    
    r1pro: 
      _target_: ${model.processor.embodiment_processors.r1lite._target_}
      shape_meta: ${data.embodiment_datasets.r1pro.shape_meta}
      num_obs_steps: ${data.obs_size}

      action_state_transforms: 
        - _target_: galaxea_fm.transforms.relative_action.RelativePoseTransform
          keys: [left_ee_pose, right_ee_pose]
        - _target_: galaxea_fm.transforms.relative_action.RelativeJointTransform
          keys: [torso]
        - _target_: galaxea_fm.transforms.rotation.PoseRotationTransform
          rotation_type: rotation_6d
          category_keys:
            action: [left_ee_pose, right_ee_pose]
            state: [left_ee_pose, right_ee_pose]

      # action & state normalization
      use_stepwise_action_norm: ${model.processor.embodiment_processors.r1lite.use_stepwise_action_norm}
      norm_default_mode: ${model.processor.embodiment_processors.r1lite.norm_default_mode}
      norm_exception_mode: ${model.processor.embodiment_processors.r1lite.norm_exception_mode}
  
      action_state_merger: ${model.processor.embodiment_processors.r1lite.action_state_merger}
      train_transforms: ${model.processor.embodiment_processors.r1lite.train_transforms}
      val_transforms: ${model.processor.embodiment_processors.r1lite.val_transforms}
      num_output_cameras: 3

      # instruction
      use_zh_instruction: False
      drop_high_level_prob: 1.0

      # tokenization
      pad_token_id: ${model.model_arch.pad_token_id}
      image_token_index: ${model.model_arch.image_token_index}
      tokenizer_params: 
        pretrained_model_name_or_path: google/paligemma-3b-pt-224
        local_files_only: False
        token: null                 # fill in the token if you access gated repo, default to None
      max_text_tokens: ${model.model_arch.max_text_tokens}
      max_image_text_tokens: ${model.model_arch.max_image_text_tokens}
      num_input_cameras: ${model.model_arch.num_input_images}
      num_image_tokens_per_camera: ${model.model_arch.vision.num_image_tokens}

    libero:
      _target_: ${model.processor.embodiment_processors.r1lite._target_}
      shape_meta: ${data.embodiment_datasets.libero.shape_meta}
      num_obs_steps: ${data.obs_size}

      action_state_transforms: null

      use_stepwise_action_norm: ${model.processor.embodiment_processors.r1lite.use_stepwise_action_norm}
      norm_default_mode: ${model.processor.embodiment_processors.r1lite.norm_default_mode}
      norm_exception_mode: null

      action_state_merger: ${model.processor.embodiment_processors.r1lite.action_state_merger}
      train_transforms: 
        image: ${model.image_transform}
        wrist_image: ${model.image_transform}
      val_transforms: ${model.processor.embodiment_processors.libero.train_transforms}
      num_output_cameras: 3

      # instruction
      use_zh_instruction: False
      drop_high_level_prob: 1.0

      # tokenization
      pad_token_id: ${model.model_arch.pad_token_id}
      image_token_index: ${model.model_arch.image_token_index}
      tokenizer_params: 
        pretrained_model_name_or_path: google/paligemma-3b-pt-224
        local_files_only: False
        token: null                 # fill in the token if you access gated repo, default to None
      max_text_tokens: ${model.model_arch.max_text_tokens}
      max_image_text_tokens: ${model.model_arch.max_image_text_tokens}
      num_input_cameras: ${model.model_arch.num_input_images}
      num_image_tokens_per_camera: ${model.model_arch.vision.num_image_tokens}


model_arch:
  _target_: galaxea_fm.models.galaxea_zero.galaxea_zero_policy.GalaxeaZeroPolicy
  model_name: galaxea_fm.models.galaxea_zero.galaxea_zero_policy.GalaxeaZero
  pretrained_model_path: /mnt/pretrained_models/google/paligemma-3b-pt-224

  vla_training_strategy: "vla-full-train" # training both vision and language
  backbone_lr_multiplier: 1.0
  image_token_index: 257152
  pad_token_id: 0
  vocab_size: 257216

  cond_steps: ${data.obs_size}
  horizon_steps: ${data.action_size}
  max_text_tokens: 55
  max_image_text_tokens: ${eval:'${model.model_arch.num_input_images} * ${model.model_arch.vision.num_image_tokens} + ${model.model_arch.max_text_tokens}'}
  num_input_images: ${eval:'${model.model_arch.cond_steps} * ${model.model_arch.vision.num_channels}'} # $data.window_size * LEN($data.camera_views)
  num_extra_image_tokens_per_camera: 0
  final_action_clip_value: null  # data normalized in [-1,1]

  action_dim: 26 # R1Lite: 2 x [Arm (6) + Gripper (1)] + Torso Velocity (6) + Chassis Velocity (6)
  proprio_dim: 24  # R1Pro: 2 * [Eef_6d (9) + Gripper (1)] + 4 (Torso) 
  action_decoder_layers: 2
  action_expert_adaptive_mode: null

  flow_sampling: beta
  num_inference_steps: 10

  vision:
    name: galaxea_fm.models.galaxea_zero.paligemma.siglip.SiglipVisionModel
    hidden_size: 1152 # siglip
    intermediate_size: 4304
    num_hidden_layers: 27
    num_attention_heads: 16
    num_channels: 3
    image_size: 224
    patch_size: 14
    layer_norm_eps: 0.000001
    attention_dropout: 0.0
    num_image_tokens: 256
  
  vision_projector:
    name: galaxea_fm.models.galaxea_zero.paligemma.siglip.PaliGemmaMultiModalProjector
    vision_config:
      hidden_size: 1152
      projection_dim: 2048
    
  joint:
    name: galaxea_fm.models.galaxea_zero.joint_model.JointModel
    action_expert_adaptive_mode: null
    mixture:
      vlm:   # gemma
        hidden_size: 2048
        intermediate_size: 16384
        use_final_norm: False
        cache: True
      proprio:
        hidden_size: 1024
        intermediate_size: 4096
        use_final_norm: True  # technically no, but sharing weights with action anyway
        cache: True
        adaptive_mode: null
      action:
        hidden_size: 1024
        intermediate_size: 4096
        use_final_norm: True
        cache: False
        adaptive_mode: null

    time_hidden_size: 256 # only applicable if using adaptive
    num_hidden_layers: 18
    num_attention_heads: 8
    num_key_value_heads: 1
    head_dim: 256
    max_position_embeddings: 8192
    rms_norm_eps: 0.000001
    rope_theta: 10000.0
    attention_bias: False
    attention_dropout: 0.0
